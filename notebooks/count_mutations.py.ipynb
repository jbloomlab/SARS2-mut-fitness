{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "154d280c-5ce4-415f-920f-16eccadcde80",
   "metadata": {},
   "source": [
    "# Count mutations from `matUtils` translated mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ca2a9-f6a9-43f4-9d15-2478fe03517a",
   "metadata": {},
   "source": [
    "Import Python modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce468909-5a1e-43eb-bcc0-7b0617a9047b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Bio.SeqIO\n",
    "\n",
    "import numpy\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fdd55a-bf0b-457a-94fb-1a4b1fc5555a",
   "metadata": {},
   "source": [
    "Get variables from `snakemake`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c89ff7-894b-4d55-9ee9-b9ae931ffcea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_nt_mutations = snakemake.params.max_nt_mutations\n",
    "max_reversions_to_ref = snakemake.params.max_reversions_to_ref\n",
    "max_reversions_to_founder = snakemake.params.max_reversions_to_clade_founder\n",
    "input_tsv = snakemake.input.tsv\n",
    "input_nt_mut_csv = snakemake.input.nt_mut_csv\n",
    "ref_fasta = snakemake.input.ref_fasta\n",
    "usher_masked_sites_yaml = snakemake.input.usher_masked_sites\n",
    "site_mask_csv = snakemake.input.site_mask\n",
    "clade_founder_fasta = snakemake.input.clade_founder_fasta\n",
    "clade = snakemake.wildcards.clade\n",
    "sites_to_exclude = snakemake.params.sites_to_exclude\n",
    "site_include_range = snakemake.params.site_include_range\n",
    "exclude_ref_to_founder_muts = snakemake.params.exclude_ref_to_founder_muts\n",
    "ref_to_founder_muts_csv = snakemake.input.ref_to_founder_muts\n",
    "output_csv = snakemake.output.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49792679-2ad9-4a59-b82b-c9d235cc5d27",
   "metadata": {},
   "source": [
    "Get reference and founder sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a679b325-6aa0-47a6-969e-a4eb1e045bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref = str(Bio.SeqIO.read(ref_fasta, \"fasta\").seq)\n",
    "founder = str(Bio.SeqIO.read(clade_founder_fasta, \"fasta\").seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce941dc-e3a2-4db1-bde7-37c0253e81c3",
   "metadata": {},
   "source": [
    "Get the sites and mutations to exclude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d029aa0e-ade3-4657-a6bb-604ce2446ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if sites_to_exclude:\n",
    "    sites_to_exclude = set(sites_to_exclude)\n",
    "else:\n",
    "    sites_to_exclude = set()\n",
    "print(f\"There are {len(sites_to_exclude)} sites to exclude\")\n",
    "\n",
    "masked_sites = set(pd.read_csv(site_mask_csv)[\"site\"])\n",
    "print(f\"There are {len(masked_sites)} masked sites\")\n",
    "sites_to_exclude = sites_to_exclude.union(masked_sites)\n",
    "\n",
    "if exclude_ref_to_founder_muts:\n",
    "    muts_to_exclude = set(pd.read_csv(ref_to_founder_muts_csv)[\"mutation\"])\n",
    "else:\n",
    "    muts_to_exclude = set()\n",
    "print(f\"There are {len(muts_to_exclude)} mutations to exclude\")\n",
    "\n",
    "with open(usher_masked_sites_yaml) as f:\n",
    "    usher_masked_sites = yaml.safe_load(f)\n",
    "for mask, mask_dict in usher_masked_sites.items():\n",
    "    if clade in mask_dict[\"clades\"]:\n",
    "        sites = mask_dict[\"sites\"]\n",
    "        print(f\"Applying UShER mask {mask} of {len(sites)} sites\")\n",
    "        sites_to_exclude = sites_to_exclude.union(sites)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2307966-9656-488a-998d-465cd6771d62",
   "metadata": {},
   "source": [
    "Process mutations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4035ee6f-33fe-4560-ab2d-4aa755734057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "translated_mat = pd.read_csv(input_tsv, sep=\"\\t\")\n",
    "\n",
    "# non-coding as well as coding\n",
    "nt_muts = pd.read_csv(input_nt_mut_csv).rename(\n",
    "    columns={\"nt_mutations\": \"nt_mutations_coding_and_noncoding\"}\n",
    ")\n",
    "\n",
    "assert len(translated_mat) <= len(nt_muts)\n",
    "assert nt_muts[\"node_id\"].nunique() >= translated_mat[\"node_id\"].nunique()\n",
    "assert set(nt_muts[\"node_id\"]).issuperset(set(translated_mat[\"node_id\"]))\n",
    "\n",
    "# expected final columns\n",
    "final_cols = [\n",
    "    'protein',\n",
    "    'aa_mutation',\n",
    "    'nt_mutation',\n",
    "    'codon_change',\n",
    "    'synonymous',\n",
    "    'noncoding',\n",
    "    'nt_site',\n",
    "    'reference_nt',\n",
    "    'clade_founder_nt',\n",
    "    'exclude',\n",
    "    'count',\n",
    "    'count_terminal',\n",
    "    'count_non_terminal',\n",
    "    'mean_log_size',\n",
    "]\n",
    "\n",
    "def get_noncoding(row):\n",
    "    \"\"\"Get just the noncoding mutations in a DataFrame row.\"\"\"\n",
    "    coding = row[\"nt_mutations\"]\n",
    "    both = row[\"nt_mutations_coding_and_noncoding\"]\n",
    "    assert set(coding).issubset(both)\n",
    "    return sorted(set(both) - set(coding))\n",
    "\n",
    "if len(translated_mat) == 0 or len(nt_muts) == 0:\n",
    "    # no data, just define an empty data frame\n",
    "    mutation_counts = pd.DataFrame(columns=final_cols)\n",
    "\n",
    "else:\n",
    "    # first filter nodes by non-coding mutation criterion\n",
    "    filtered_nodes = (\n",
    "        translated_mat\n",
    "        # this next merge will drop nodes with only noncoding mutations\n",
    "        .merge(nt_muts, on=\"node_id\", validate=\"one_to_one\")\n",
    "        .query(\"not nt_mutations.str.contains(',')\")\n",
    "        .assign(\n",
    "            nt_mutations=lambda x: x[\"nt_mutations\"].str.split(\";\"),\n",
    "            nt_mutations_coding_and_noncoding=lambda x: x[\"nt_mutations_coding_and_noncoding\"].str.split(\";\"),\n",
    "            codon_changes=lambda x: x[\"codon_changes\"].str.split(\";\"),\n",
    "            aa_mutations=lambda x: x[\"aa_mutations\"].str.split(\";\"),\n",
    "            noncoding_nt_mutations=lambda x: x.apply(get_noncoding, axis=1),\n",
    "            n_nt_mutations=lambda x: x[\"nt_mutations\"].map(lambda ms: len(set(ms))),\n",
    "            n_reversions_to_ref=lambda x: x[\"nt_mutations\"].map(\n",
    "                lambda ms: sum(m[-1] == ref[int(m[1:-1]) - 1] for m in set(ms))\n",
    "            ),\n",
    "            n_reversions_to_founder=lambda x: x[\"nt_mutations\"].map(\n",
    "                lambda ms: sum(m[-1] == founder[int(m[1:-1]) - 1] for m in set(ms))\n",
    "            ),\n",
    "            is_terminal=lambda x: x[\"leaves_sharing_mutations\"] == 1,\n",
    "            log_size=lambda x: numpy.log(x[\"leaves_sharing_mutations\"].clip(lower=1)),\n",
    "        )\n",
    "        .drop(columns=\"nt_mutations_coding_and_noncoding\")\n",
    "        .query(\"n_reversions_to_ref <= @max_reversions_to_ref\")\n",
    "        .query(\"n_reversions_to_founder <= @max_reversions_to_founder\")\n",
    "        .query(\"n_nt_mutations <= @max_nt_mutations\")\n",
    "    )\n",
    "\n",
    "    # get information on coding mutations\n",
    "    coding_mutations = (\n",
    "        filtered_nodes\n",
    "        .drop(columns=\"noncoding_nt_mutations\")\n",
    "        .explode([\"aa_mutations\", \"nt_mutations\", \"codon_changes\"])\n",
    "        .assign(\n",
    "            protein=lambda x: x[\"aa_mutations\"].str.split(\":\").str[0],\n",
    "            aa_mutation=lambda x: x[\"aa_mutations\"].str.split(\":\").str[1],\n",
    "            synonymous=lambda x: x[\"aa_mutation\"].map(lambda m: m[0] == m[-1]),\n",
    "        )\n",
    "        .rename(columns={\"nt_mutations\": \"nt_mutation\", \"codon_changes\": \"codon_change\"})\n",
    "        .groupby([\"node_id\", \"nt_mutation\", \"is_terminal\", \"log_size\"], as_index=False)\n",
    "        .aggregate(\n",
    "            protein=pd.NamedAgg(\"protein\", lambda s: \";\".join(s)),\n",
    "            aa_mutation=pd.NamedAgg(\"aa_mutation\", lambda s: \";\".join(s)),\n",
    "            codon_change=pd.NamedAgg(\"codon_change\", lambda s: \";\".join(s)),\n",
    "            synonymous=pd.NamedAgg(\"synonymous\", \"all\"),\n",
    "        )\n",
    "        .assign(noncoding=False)\n",
    "    )\n",
    "\n",
    "    # get information on non-coding mutations\n",
    "    noncoding_mutations = (\n",
    "        filtered_nodes\n",
    "        .drop(columns=[\"aa_mutations\", \"nt_mutations\", \"codon_changes\"])\n",
    "        .explode(\"noncoding_nt_mutations\")\n",
    "        .rename(columns={\"noncoding_nt_mutations\": \"nt_mutation\"})\n",
    "        .query(\"nt_mutation.notnull()\")\n",
    "        .assign(\n",
    "            aa_mutation=\"noncoding\",\n",
    "            codon_change=\"noncoding\",\n",
    "            protein=\"noncoding\",\n",
    "            synonymous=False,\n",
    "            noncoding=True,\n",
    "        )\n",
    "        [coding_mutations.columns]\n",
    "    )\n",
    "\n",
    "    # combine noncoding and coding mutations\n",
    "    mutations = pd.concat([coding_mutations, noncoding_mutations],ignore_index=True)\n",
    "\n",
    "    mutation_counts_tidy = (\n",
    "        pd.concat(\n",
    "            [\n",
    "                mutations.assign(terminal_nodes_only=False),\n",
    "                mutations.query(\"is_terminal\").assign(terminal_nodes_only=True),\n",
    "            ],\n",
    "        )\n",
    "        .drop(columns=\"is_terminal\")\n",
    "        .groupby(\n",
    "            [\n",
    "                \"terminal_nodes_only\",\n",
    "                \"protein\",\n",
    "                \"aa_mutation\",\n",
    "                \"nt_mutation\",\n",
    "                \"codon_change\",\n",
    "                \"synonymous\",\n",
    "                \"noncoding\",\n",
    "            ],\n",
    "            as_index=False,\n",
    "            dropna=False,\n",
    "        )\n",
    "        .aggregate(\n",
    "            count=pd.NamedAgg(\"node_id\", \"count\"),\n",
    "            mean_log_size=pd.NamedAgg(\"log_size\", \"mean\"),\n",
    "        )\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "        .assign(\n",
    "            nt_site=lambda x: x[\"nt_mutation\"].str[1:-1].astype(int),\n",
    "            reference_nt=lambda x: x[\"nt_site\"].map(lambda r: ref[r - 1]),\n",
    "            clade_founder_nt=lambda x: x[\"nt_site\"].map(lambda r: founder[r - 1]),\n",
    "            exclude=lambda x: (\n",
    "                x[\"nt_site\"].isin(sites_to_exclude)\n",
    "                | x[\"nt_mutation\"].isin(muts_to_exclude)\n",
    "                | (x[\"nt_site\"] < site_include_range[\"start\"])\n",
    "                | (x[\"nt_site\"] > site_include_range[\"end\"])\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    mutation_counts = (\n",
    "        mutation_counts_tidy\n",
    "        .assign(terminal_nodes_only=lambda x: x[\"terminal_nodes_only\"].map({False: \"count\", True: \"count_terminal\"}))\n",
    "        .pivot_table(\n",
    "            index=[\n",
    "                c for c in mutation_counts_tidy.columns\n",
    "                if c not in {\"count\", \"terminal_nodes_only\", \"mean_log_size\"}\n",
    "            ],\n",
    "            values=\"count\",\n",
    "            columns=\"terminal_nodes_only\",\n",
    "            fill_value=0,\n",
    "        )\n",
    "        .assign(\n",
    "            # first add empty columns if empty data frame\n",
    "            count=lambda x: x[\"count\"] if \"count\" in x.columns else 0,\n",
    "            count_terminal=lambda x: x[\"count_terminal\"] if \"count_terminal\" in x.columns else 0,\n",
    "            # compute non-terminal counts\n",
    "            count_non_terminal=lambda x: x[\"count\"] - x[\"count_terminal\"],\n",
    "        )\n",
    "        .sort_values(\"count\", ascending=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # add log node size\n",
    "    mutation_counts = mutation_counts.merge(\n",
    "        (\n",
    "            mutation_counts_tidy\n",
    "            .query(\"not terminal_nodes_only\")\n",
    "            [[\"protein\", \"aa_mutation\", \"nt_mutation\", \"codon_change\", \"mean_log_size\"]]\n",
    "        ),\n",
    "        on=[\"protein\", \"aa_mutation\", \"nt_mutation\", \"codon_change\"],\n",
    "        how=\"outer\",\n",
    "        validate=\"one_to_one\",\n",
    "    )\n",
    "    assert mutation_counts[\"mean_log_size\"].notnull().all()\n",
    "\n",
    "assert mutation_counts.columns.tolist() == final_cols\n",
    "    \n",
    "mutation_counts.to_csv(output_csv, index=False)\n",
    "\n",
    "mutation_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c97ad-540b-45d1-8109-023ead710b60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
